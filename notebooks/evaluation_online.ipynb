{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Evaluation\n",
    "\n",
    "We pretrain a PMF model as the environment simulator, i.e., to predict an item's feedback that the user never rates before. The online evaluation procedure follows the Training Algorithm, i.e., the parameters continuously update during the online evaluation stage. Its major difference is that the feedback of a recommended item is observed by the environment simulator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1NmejTIFPtf"
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "#Dependencies\n",
    "import os\n",
    "import json \n",
    "import yaml\n",
    "import pickle\n",
    "from random import sample\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.environment import OfflineEnv, OfflineFairEnv\n",
    "from src.model.recommender import DRRAgent, FairRecAgent\n",
    "\n",
    "from src.recsys_fair_metrics.recsys_fair import RecsysFair\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import recmetrics as rm\n",
    "\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "ENV = dict(drr=OfflineEnv, fairrec=OfflineFairEnv)\n",
    "AGENT = dict(drr=DRRAgent, fairrec=FairRecAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"movie_lens_100k\"\n",
    "dataset_path = \"../data/{}_output_path.json\".format(dataset_name)\n",
    "with open(dataset_path) as json_file:\n",
    "    _dataset_path = json.load(json_file)\n",
    "\n",
    "\n",
    "dataset = {}\n",
    "with open(os.path.join(\"..\", _dataset_path[\"eval_users_dict\"]), \"rb\") as pkl_file:\n",
    "    dataset[\"eval_users_dict\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(os.path.join(\"..\", _dataset_path[\"eval_users_history_lens\"]), \"rb\") as pkl_file:\n",
    "    dataset[\"eval_users_history_lens\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(os.path.join(\"..\", _dataset_path[\"users_history_lens\"]), \"rb\") as pkl_file:\n",
    "    dataset[\"users_history_lens\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(os.path.join(\"..\", _dataset_path[\"item_groups\"]), \"rb\") as pkl_file:\n",
    "    dataset[\"item_groups\"] = pickle.load(pkl_file)\n",
    "\n",
    "item_groups_df = pd.DataFrame(dataset[\"item_groups\"].items(), columns=[\"item_id\", \"group\"])\n",
    "catalog = item_groups_df.item_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor-Critic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drr_train_ids = [\n",
    "    \"movie_lens_100k_2022-03-23_16-59-47\"\n",
    "]\n",
    "\n",
    "fairrec_train_ids = [   \n",
    "    \"movie_lens_100k_fair_2022-03-23_16-59-43\"\n",
    "]\n",
    "\n",
    "idx = -1\n",
    "\n",
    "\n",
    "algorithm = \"fairrec\"\n",
    "train_version = dataset_name if algorithm == \"drr\" else \"{}_fair\".format(dataset_name)\n",
    "train_id = drr_train_ids[idx] if algorithm == \"drr\" else fairrec_train_ids[idx]\n",
    "output_path = \"../model/{}/{}\".format(train_version, train_id)\n",
    "\n",
    "path = os.path.abspath(\n",
    "    os.path.join(output_path, \"{}.yaml\".format(train_version))\n",
    ")\n",
    "with open(path) as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "no_cuda = False\n",
    "top_k = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(_dataset_path[\"ratings_df\"])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "rm.long_tail_plot(\n",
    "    df=ratings, \n",
    "    item_id_column=\"movie_id\", \n",
    "    interaction_type=\"items clicked\", \n",
    "    percentage=0.5,\n",
    "    x_labels=False\n",
    ")\n",
    "plt.savefig(os.path.join(output_path, \"long_tail_plot.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_precision = []\n",
    "_propfair = []\n",
    "_ufg = []\n",
    "for i in range(1):\n",
    "    sum_precision = 0\n",
    "    sum_propfair = 0\n",
    "    sum_reward = 0\n",
    "\n",
    "    recommended_item = []\n",
    "    random_recommended_item = []\n",
    "\n",
    "    env = ENV[algorithm](\n",
    "        users_dict=dataset[\"eval_users_dict\"],\n",
    "        users_history_lens=dataset[\"eval_users_history_lens\"],\n",
    "        n_groups=config[\"model_train\"][\"n_groups\"],\n",
    "        item_groups=dataset[\"item_groups\"],\n",
    "        state_size=config[\"model_train\"][\"state_size\"],\n",
    "        done_count=config[\"model_train\"][\"done_count\"],\n",
    "        fairness_constraints=config[\"model_train\"][\"fairness_constraints\"],\n",
    "        reward_threshold=config[\"model_train\"][\"reward_threshold\"],\n",
    "        use_only_reward_model=True,\n",
    "    )\n",
    "    available_users = env.available_users\n",
    "\n",
    "    recommender = AGENT[algorithm](\n",
    "        env=env,\n",
    "        train_version=train_version,\n",
    "        is_test=True,\n",
    "        model_path=output_path,\n",
    "        users_num=config[\"model_train\"][\"users_num\"],\n",
    "        items_num=config[\"model_train\"][\"items_num\"],\n",
    "        embedding_dim=config[\"model_train\"][\"embedding_dim\"],\n",
    "        srm_size=config[\"model_train\"][\"srm_size\"],\n",
    "        state_size=config[\"model_train\"][\"state_size\"],\n",
    "        actor_hidden_dim=config[\"model_train\"][\"actor_hidden_dim\"],\n",
    "        actor_learning_rate=config[\"model_train\"][\"actor_learning_rate\"],\n",
    "        critic_hidden_dim=config[\"model_train\"][\"critic_hidden_dim\"],\n",
    "        critic_learning_rate=config[\"model_train\"][\"critic_learning_rate\"],\n",
    "        discount_factor=config[\"model_train\"][\"discount_factor\"],\n",
    "        tau=config[\"model_train\"][\"tau\"],\n",
    "        learning_starts=1,#config[\"model_train\"][\"learning_starts\"],\n",
    "        replay_memory_size=config[\"model_train\"][\"replay_memory_size\"],\n",
    "        batch_size=1,#config[\"model_train\"][\"batch_size\"],\n",
    "        embedding_network_weights_path=\"../{}\".format(config[\"model_train\"][\"embedding_network_weights\"]),\n",
    "        n_groups=config[\"model_train\"][\"n_groups\"],\n",
    "        fairness_constraints=config[\"model_train\"][\"fairness_constraints\"],\n",
    "        use_reward_model=config[\"model_train\"][\"use_reward_model\"],\n",
    "    )\n",
    "\n",
    "    for user_id in tqdm(available_users):\n",
    "\n",
    "        eval_env = ENV[algorithm](\n",
    "            users_dict=dataset[\"eval_users_dict\"],\n",
    "            users_history_lens=dataset[\"eval_users_history_lens\"],\n",
    "            n_groups=config[\"model_train\"][\"n_groups\"],\n",
    "            item_groups=dataset[\"item_groups\"],\n",
    "            state_size=config[\"model_train\"][\"state_size\"],\n",
    "            done_count=config[\"model_train\"][\"done_count\"],\n",
    "            fairness_constraints=config[\"model_train\"][\"fairness_constraints\"],\n",
    "            reward_threshold=config[\"model_train\"][\"reward_threshold\"],\n",
    "            fix_user_id=user_id,\n",
    "            reward_model=recommender.reward_model,\n",
    "            device=recommender.device,\n",
    "            use_only_reward_model=True,\n",
    "        )\n",
    "\n",
    "        recommender.env = eval_env\n",
    "\n",
    "        # recommender.buffer = pickle.load(open(os.path.join(output_path, \"buffer.pkl\"), \"rb\"))\n",
    "\n",
    "        precision, ndcg, propfair, reward, list_recommended_item = recommender.train(\n",
    "            max_episode_num=1, top_k=top_k, load_model=True\n",
    "        )\n",
    "        recommended_item.append(list_recommended_item)\n",
    "        random_recommended_item.append({user_id: sample(catalog, config[\"model_train\"][\"done_count\"])})\n",
    "\n",
    "        sum_precision += precision\n",
    "        sum_propfair += propfair\n",
    "        sum_reward += reward\n",
    "\n",
    "        del eval_env\n",
    "\n",
    "\n",
    "    _precision.append(sum_precision / len(dataset[\"eval_users_dict\"]))\n",
    "    _propfair.append(sum_propfair / len(dataset[\"eval_users_dict\"]))\n",
    "    _ufg.append((sum_propfair / len(dataset[\"eval_users_dict\"]))\n",
    "        / (1 - (sum_precision / len(dataset[\"eval_users_dict\"]))))\n",
    "\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"PropFair \", round(np.mean(_propfair), 4))\n",
    "print(\"Precision \", round(np.mean(_precision), 4))\n",
    "print(\"UFG \", round(np.mean(_ufg), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure([\n",
    "    go.Bar(\n",
    "        x=[\"precision\", \"prop_fair\", \"ufg\"],\n",
    "        y=[round(np.mean(_precision), 4), round(np.mean(_propfair), 4), round(np.mean(_ufg), 4)],\n",
    "        text=[round(np.mean(_precision), 4), round(np.mean(_propfair), 4), round(np.mean(_ufg), 4)],\n",
    "        textposition=\"auto\",\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Fair Metrics\",\n",
    "    template=\"ggplot2\",\n",
    "    width=1000, \n",
    "    font=dict(size=16)\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(output_path, \"metrics.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = pd.DataFrame([i.values() for i in recommended_item], columns=[\"sorted_actions\"]).sorted_actions.values.tolist()\n",
    "random_recs = pd.DataFrame([i.values() for i in random_recommended_item], columns=[\"sorted_actions\"]).sorted_actions.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = rm.prediction_coverage(recs, catalog)\n",
    "random_coverage = rm.prediction_coverage(random_recs, catalog)\n",
    "fig = go.Figure([\n",
    "    go.Bar(\n",
    "        x=[train_version, \"random\"],\n",
    "        y=[coverage, random_coverage],\n",
    "        text=[coverage, random_coverage],\n",
    "        textposition=\"auto\",\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Catalog Coverage in %\",\n",
    "    template=\"ggplot2\",\n",
    "    yaxis_title=\"coverage\",\n",
    "    yaxis = dict(\n",
    "        ticksuffix=\"%\",\n",
    "    ),\n",
    "    width=1000, \n",
    "    font=dict(size=16)\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(output_path, \"coverage.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalization = round(rm.personalization(recs) * 100, 2)\n",
    "random_personalization = round(rm.personalization(random_recs) * 100, 2)\n",
    "fig = go.Figure([\n",
    "    go.Bar(\n",
    "        x=[train_version, \"random\"],\n",
    "        y=[personalization, random_personalization],\n",
    "        text=[personalization, random_personalization],\n",
    "        textposition=\"auto\",\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Personalization\",\n",
    "    template=\"ggplot2\",\n",
    "    yaxis_title=\"personalization\",\n",
    "    yaxis = dict(\n",
    "        ticksuffix = \"%\",\n",
    "    ),\n",
    "    width=1000, \n",
    "    font=dict(size=16)\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(output_path, \"personalization.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(item_groups_df[[\"item_id\"]].apply(lambda x: recommender.get_items_emb(x).cpu().numpy().tolist())[\"item_id\"].tolist())\n",
    "\n",
    "intra_list_similarity = rm.intra_list_similarity(recs, feature_df)\n",
    "random_intra_list_similarity = rm.intra_list_similarity(random_recs, feature_df)\n",
    "\n",
    "fig = go.Figure([\n",
    "    go.Bar(\n",
    "        x=[train_version, \"random\"],\n",
    "        y=[intra_list_similarity, random_intra_list_similarity],\n",
    "        text=[intra_list_similarity, random_intra_list_similarity],\n",
    "        textposition=\"auto\",\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Intra-list Similarity\",\n",
    "    template=\"ggplot2\",\n",
    "    yaxis_title=\"similarity\",\n",
    "    # yaxis = dict(\n",
    "    #     ticksuffix = \"%\",\n",
    "    # ),\n",
    "    width=1000, \n",
    "    font=dict(size=16)\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(output_path, \"intra_list_similarity.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame([i.values() for i in recommended_item], columns=[\"sorted_actions\"])\n",
    "_df[\"user_id\"] = [list(i.keys())[0] for i in recommended_item]\n",
    "_item_metadata = pd.DataFrame(dataset[\"item_groups\"].items(), columns=[\"item_id\", \"group\"])\n",
    "\n",
    "user_column = \"user_id\"\n",
    "item_column = \"item_id\"\n",
    "reclist_column = \"sorted_actions\"\n",
    "\n",
    "recsys_fair = RecsysFair(\n",
    "    df = _df, \n",
    "    supp_metadata = _item_metadata,\n",
    "    user_column = user_column, \n",
    "    item_column = item_column, \n",
    "    reclist_column = reclist_column, \n",
    ")\n",
    "\n",
    "fair_column = \"group\"\n",
    "ex = recsys_fair.exposure(fair_column, config[\"model_train\"][\"done_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ex.show(kind='per_group_norm', column=fair_column)\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(output_path, \"exposure_per_group.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ex.show(kind='per_rank_pos', column=fair_column)\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(output_path, \"exposure_per_rank.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "RL_ActorCritic_DDPG_Movie_Recommendation.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "8842d3533bae659e5f41b6e8512932590b59a54a4b7636cc41bd679d9b5f82e4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('recsysrl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

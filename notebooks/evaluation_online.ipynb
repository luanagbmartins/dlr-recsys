{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Evaluation\n",
    "\n",
    "We pretrain a PMF model as the environment simulator, i.e., to predict an item's feedback that the user never rates before. The online evaluation procedure follows the Training Algorithm, i.e., the parameters continuously update during the online evaluation stage. Its major difference is that the feedback of a recommended item is observed by the environment simulator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1NmejTIFPtf"
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "#Dependencies\n",
    "import os\n",
    "import json \n",
    "import yaml\n",
    "import pickle\n",
    "from random import sample\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.environment import OfflineEnv, OfflineFairEnv\n",
    "from src.model.recommender import DRRAgent, FairRecAgent\n",
    "\n",
    "from src.recsys_fair_metrics.recsys_fair import RecsysFair\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import recmetrics as rm\n",
    "\n",
    "\n",
    "ENV = dict(drr=OfflineEnv, fairrec=OfflineFairEnv)\n",
    "AGENT = dict(drr=DRRAgent, fairrec=FairRecAgent)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"yelp_pd\"\n",
    "dataset_path = \"../data/{}_output_path.json\".format(dataset_name)\n",
    "with open(dataset_path) as json_file:\n",
    "    _dataset_path = json.load(json_file)\n",
    "\n",
    "\n",
    "dataset = {}\n",
    "with open(os.path.join(\"..\", _dataset_path[\"eval_users_dict\"]), \"rb\") as pkl_file:\n",
    "    dataset[\"eval_users_dict\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(os.path.join(\"..\", _dataset_path[\"eval_users_history_lens\"]), \"rb\") as pkl_file:\n",
    "    dataset[\"eval_users_history_lens\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(os.path.join(\"..\", _dataset_path[\"users_history_lens\"]), \"rb\") as pkl_file:\n",
    "    dataset[\"users_history_lens\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(os.path.join(\"..\", _dataset_path[\"item_groups\"]), \"rb\") as pkl_file:\n",
    "    dataset[\"item_groups\"] = pickle.load(pkl_file)\n",
    "\n",
    "dataset[\"items_df\"] = pd.read_csv(os.path.join(\"..\", _dataset_path[\"items_df\"]))\n",
    "dataset[\"items_metadata\"] = pd.read_csv(os.path.join(\"..\", _dataset_path[\"items_metadata\"]))\n",
    "item_groups_df = pd.DataFrame(dataset[\"item_groups\"].items(), columns=[\"item_id\", \"group\"])\n",
    "catalog = item_groups_df.item_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor-Critic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drr_train_ids = {\n",
    "    0: \"movie_lens_1m_2022-04-06_11-29-07\", # drr paper\n",
    "    1: \"movie_lens_1m_2022-04-05_16-33-30\", # drr ceia\n",
    "\n",
    "    2: \"movie_lens_100k_2022-04-07_15-40-33\", # drr paper\n",
    "    3: \"movie_lens_100k_2022-04-07_15-39-45\", # drr ceia\n",
    "    4: \"movie_lens_100k_2022-02-01_15-35-49\", # drr ceia\n",
    "\n",
    "    5: \"movie_lens_100k_2022-07-06_11-14-27\",\n",
    "    6: \"movie_lens_100k_2022-07-06_12-19-24\",\n",
    "\n",
    "    7: \"yelp_pd_2022-07-06_18-02-45\",\n",
    "    8: \"yelp_pd_2022-07-06_18-03-18\",\n",
    "    9: \"yelp_pd_2022-07-06_22-30-51\"\n",
    "    \n",
    "}\n",
    "\n",
    "fairrec_train_ids = {   \n",
    "    # Paper\n",
    "    \"p-0\": \"movie_lens_1m_fair_2022-04-05_21-33-12\",\n",
    "    \"p-1\": \"movie_lens_100k_fair_2022-04-07_22-03-32\",\n",
    "    \"p-2\": \"movie_lens_100k_fair_2022-04-18_16-24-27\",\n",
    "    \"p-3\": \"movie_lens_100k_fair_2022-04-20_18-52-34\",\n",
    "    \"p-4\": \"movie_lens_100k_fair_2022-02-01_18-49-14\", \n",
    "\n",
    "    \"p-5\": \"yelp_ca_fair_2022-06-16_12-33-16\",\n",
    "    \"p-6\": \"yelp_tn_fair_2022-06-16_15-27-06\",\n",
    "    \"p-7\": \"yelp_fl_fair_2022-06-16_16-37-20\",\n",
    "    \"p-8\": \"yelp_pa_fair_2022-06-16_17-42-17\",\n",
    "    \"p-9\": \"yelp_pd_fair_2022-06-23_18-10-53\",\n",
    "\n",
    "    # Adaptative\n",
    "    \"a-0\": \"movie_lens_100k_fair_2022-02-03_14-10-48\",\n",
    "    \"a-1\": \"movie_lens_100k_fair_2022-02-04_09-59-46\",\n",
    "\n",
    "    \"a-2\": \"movie_lens_1m_fair_2022-04-06_09-10-12\",\n",
    "    \"a-3\": \"movie_lens_100k_fair_2022-04-07_16-52-53\",\n",
    "    \"a-4\": \"movie_lens_100k_fair_2022-04-14_09-55-40\", # 0.6\n",
    "    \"a-5\": \"movie_lens_100k_fair_2022-04-14_15-13-32\", # 0.55\n",
    "    \"a-6\": \"movie_lens_100k_fair_2022-04-18_11-03-25\", # genre 0.55\n",
    "    \"a-7\": \"movie_lens_100k_fair_2022-04-18_11-06-22\", # title 0.55\n",
    "    \"a-8\": \"movie_lens_100k_fair_2022-04-19_09-14-01\", # genre 0.5\n",
    "    \"a-9\": \"movie_lens_100k_fair_2022-04-19_09-24-16\", # title 0.76\n",
    "    \"a-10\": \"movie_lens_100k_fair_2022-04-20_18-51-43\", # genre 0.58\n",
    "\n",
    "    \"a-11\": \"movie_lens_100k_fair_2022-04-25_22-49-01\", # genre + title v3 0.5\n",
    "    \"a-12\": \"movie_lens_100k_fair_2022-04-25_22-53-17\", # title v3 0.5\n",
    "    \"a-13\": \"movie_lens_100k_fair_2022-04-26_07-39-21\", # genre 0.5\n",
    "\n",
    "    \"a-14\": \"movie_lens_100k_fair_2022-04-26_12-27-11\", # title v2 0.5\n",
    "    \"a-15\": \"movie_lens_100k_fair_2022-04-26_12-28-13\", # genre + title v2 0.5\"\n",
    "\n",
    "    \"a-16\": \"movie_lens_100k_fair_2022-04-29_12-36-02\", # genre + title v2 0.5\n",
    "    \"a-17\": \"movie_lens_100k_fair_2022-05-05_11-28-10\", # genre + title v2 0.51\n",
    "    \"a-18\": \"movie_lens_100k_fair_2022-05-05_14-54-51\", # genre + title v2 0.52\n",
    "    \"a-19\": \"movie_lens_100k_fair_2022-05-05_18-11-37\", # genre + title v2 0.53\n",
    "    \"a-20\": \"movie_lens_100k_fair_2022-05-05_21-23-33\", # genre + title v2 0.54\n",
    "    \"a-21\": \"movie_lens_100k_fair_2022-05-06_00-32-23\", # genre + title v2 0.55\n",
    "    \"a-22\": \"movie_lens_100k_fair_2022-05-05_11-28-46\", # genre + title v2 0.56\n",
    "    \"a-23\": \"movie_lens_100k_fair_2022-05-05_14-51-34\", # genre + title v2 0.57\n",
    "    \"a-24\": \"movie_lens_100k_fair_2022-05-05_18-06-41\", # genre + title v2 0.58\n",
    "    \"a-25\": \"movie_lens_100k_fair_2022-05-05_21-21-03\", # genre + title v2 0.59\n",
    "    \"a-26\": \"movie_lens_100k_fair_2022-05-06_00-29-50\", # genre + title v2 0.6\n",
    "    \"a-27\": \"movie_lens_100k_fair_2022-05-06_03-47-52\", # genre + title v2 0.61\n",
    "    \"a-28\": \"movie_lens_100k_fair_2022-05-06_06-54-07\", # genre + title v2 0.62\n",
    "    \"a-29\": \"movie_lens_100k_fair_2022-05-06_03-47-59\", # genre + title v2 0.63 \n",
    "    \"a-30\": \"movie_lens_100k_fair_2022-05-06_06-54-00\", # genre + title v2 0.64\n",
    "    \"a-31\": \"movie_lens_100k_fair_2022-05-06_10-09-00\", # genre + title v2 0.65\n",
    "    \"a-32\": \"movie_lens_100k_fair_2022-05-06_10-12-07\", # genre + title v2 0.66\n",
    "   \n",
    "    # Combining\n",
    "    \"c-0\": \"movie_lens_1m_fair_2022-04-05_23-46-04\",\n",
    "    \"c-1\": \"movie_lens_100k_fair_2022-04-07_17-56-50\",\n",
    "    \"c-2\": \"movie_lens_100k_fair_2022-04-24_17-38-08\", # genre\n",
    "    \"c-3\": \"movie_lens_100k_fair_2022-04-24_17-38-39\", # title v1\n",
    "    \"c-4\": \"movie_lens_100k_fair_2022-04-24_21-58-41\", # title v2\n",
    "    \"c-5\": \"movie_lens_100k_fair_2022-04-24_22-01-39\", # genre + title v2 \n",
    "\n",
    "    \"c-6\": \"movie_lens_100k_fair_2022-04-25_19-31-54\", # title v3\n",
    "    \"c-7\": \"movie_lens_100k_fair_2022-04-25_19-32-40\", # genre + title v3\n",
    "    \"c-8\": \"movie_lens_100k_fair_2022-04-26_17-45-20\", # item genre bert\n",
    "    \"c-9\": \"movie_lens_100k_fair_2022-04-26_17-48-20\", # item genre date\n",
    "   \n",
    "}\n",
    "\n",
    "idx = 7\n",
    "\n",
    "algorithm = \"drr\"\n",
    "train_version = dataset_name if algorithm == \"drr\" else \"{}_fair\".format(dataset_name)\n",
    "train_id = drr_train_ids[idx] if algorithm == \"drr\" else fairrec_train_ids[idx]\n",
    "output_path = \"../model/{}/{}\".format(train_version, train_id)\n",
    "\n",
    "path = os.path.abspath(\n",
    "    os.path.join(output_path, \"{}.yaml\".format(train_version))\n",
    ")\n",
    "with open(path) as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "no_cuda = False\n",
    "top_k = [3, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_bert_emb = [\n",
    "    \"item_title_emb\",\n",
    "    \"item_title_genre_emb\",\n",
    "    \"item_genre_emb_bert\",\n",
    "    \"item_genre_date_emb\",\n",
    "]\n",
    "bert = None\n",
    "if config[\"model_train\"][\"user_intent\"] in _bert_emb:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "\n",
    "    bert = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Reward Model:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2181/2181 [02:52<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Reward Model:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2181/2181 [03:50<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Reward Model:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2181/2181 [06:49<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Reward Model:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2181/2181 [09:50<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "_precision = []\n",
    "_propfair = []\n",
    "_ufg = []\n",
    "_recommended_item = []\n",
    "_random_recommended_item = []\n",
    "_sum_reward = []\n",
    "for k in top_k:\n",
    "    sum_precision = 0\n",
    "    sum_propfair = 0\n",
    "    sum_reward = 0\n",
    "\n",
    "    recommended_item = []\n",
    "    random_recommended_item = []\n",
    "\n",
    "    env = ENV[algorithm](\n",
    "        users_dict=dataset[\"eval_users_dict\"],\n",
    "        users_history_lens=dataset[\"eval_users_history_lens\"],\n",
    "        n_groups=config[\"model_train\"][\"n_groups\"],\n",
    "        item_groups=dataset[\"item_groups\"],\n",
    "        state_size=config[\"model_train\"][\"state_size\"],\n",
    "        done_count=k,\n",
    "        fairness_constraints=config[\"model_train\"][\"fairness_constraints\"],\n",
    "        reward_threshold=config[\"model_train\"][\"reward_threshold\"],\n",
    "        reward_version=config[\"model_train\"][\"reward_version\"],\n",
    "        use_only_reward_model=True,\n",
    "        items_metadata=dataset[\"items_metadata\"],\n",
    "        items_df=dataset[\"items_df\"],\n",
    "        user_intent_threshold=config[\"model_train\"][\"user_intent_threshold\"],\n",
    "        user_intent=config[\"model_train\"][\"user_intent\"],\n",
    "    )\n",
    "    env.bert = bert\n",
    "    available_users = env.available_users\n",
    "\n",
    "    recommender = AGENT[algorithm](\n",
    "        env=env,\n",
    "        is_test=True,\n",
    "        train_version=\"{}_{}\".format(train_version, config[\"model_train\"][\"reward_version\"]),\n",
    "        model_path=output_path,\n",
    "        users_num=config[\"model_train\"][\"users_num\"],\n",
    "        items_num=config[\"model_train\"][\"items_num\"],\n",
    "        embedding_dim=config[\"model_train\"][\"embedding_dim\"],\n",
    "        srm_size=config[\"model_train\"][\"srm_size\"],\n",
    "        state_size=config[\"model_train\"][\"state_size\"],\n",
    "        actor_hidden_dim=config[\"model_train\"][\"actor_hidden_dim\"],\n",
    "        actor_learning_rate=config[\"model_train\"][\"actor_learning_rate\"],\n",
    "        critic_hidden_dim=config[\"model_train\"][\"critic_hidden_dim\"],\n",
    "        critic_learning_rate=config[\"model_train\"][\"critic_learning_rate\"],\n",
    "        discount_factor=config[\"model_train\"][\"discount_factor\"],\n",
    "        tau=config[\"model_train\"][\"tau\"],\n",
    "        learning_starts=1, # config[\"model_train\"][\"learning_starts\"],\n",
    "        replay_memory_size=config[\"model_train\"][\"replay_memory_size\"],\n",
    "        batch_size=1, # config[\"model_train\"][\"batch_size\"],\n",
    "        embedding_network_weights_path=\"../{}\".format(config[\"model_train\"][\"embedding_network_weights\"]),\n",
    "        n_groups=config[\"model_train\"][\"n_groups\"],\n",
    "        fairness_constraints=config[\"model_train\"][\"fairness_constraints\"],\n",
    "        use_reward_model=config[\"model_train\"][\"use_reward_model\"],\n",
    "    )\n",
    "\n",
    "    for user_id in tqdm(available_users):\n",
    "\n",
    "        eval_env = ENV[algorithm](\n",
    "            users_dict=dataset[\"eval_users_dict\"],\n",
    "            users_history_lens=dataset[\"eval_users_history_lens\"],\n",
    "            n_groups=config[\"model_train\"][\"n_groups\"],\n",
    "            item_groups=dataset[\"item_groups\"],\n",
    "            state_size=config[\"model_train\"][\"state_size\"],\n",
    "            done_count=k, \n",
    "            fairness_constraints=config[\"model_train\"][\"fairness_constraints\"],\n",
    "            reward_threshold=config[\"model_train\"][\"reward_threshold\"],\n",
    "            reward_version=config[\"model_train\"][\"reward_version\"],\n",
    "            fix_user_id=user_id,\n",
    "            reward_model=recommender.reward_model,\n",
    "            device=recommender.device,\n",
    "            use_only_reward_model=True,\n",
    "            items_metadata=dataset[\"items_metadata\"],\n",
    "            items_df=dataset[\"items_df\"],\n",
    "            user_intent_threshold=config[\"model_train\"][\"user_intent_threshold\"],\n",
    "            user_intent=config[\"model_train\"][\"user_intent\"],\n",
    "        )\n",
    "        eval_env.bert = bert\n",
    "\n",
    "        # recommender.buffer = pickle.load(open(os.path.join(output_path, \"buffer.pkl\"), \"rb\"))\n",
    "\n",
    "        precision, ndcg, propfair, reward, list_recommended_item, _, _ = recommender.online_evaluate(\n",
    "            top_k=False, load_model=True, env = eval_env\n",
    "        )\n",
    "\n",
    "        recommended_item.append(list_recommended_item)\n",
    "        random_recommended_item.append({user_id: sample(catalog, k)})\n",
    "\n",
    "        sum_precision += precision\n",
    "        sum_propfair += propfair\n",
    "        sum_reward += reward\n",
    "\n",
    "        del eval_env\n",
    "\n",
    "\n",
    "    _precision.append(sum_precision / len(dataset[\"eval_users_dict\"]))\n",
    "    _propfair.append(sum_propfair / len(dataset[\"eval_users_dict\"]))\n",
    "    _ufg.append((sum_propfair / len(dataset[\"eval_users_dict\"]))\n",
    "        / (1 - (sum_precision / len(dataset[\"eval_users_dict\"]))))\n",
    "    _recommended_item.append(recommended_item)\n",
    "    _random_recommended_item.append(random_recommended_item)\n",
    "    _sum_reward.append(sum_reward / len(dataset[\"eval_users_dict\"]))\n",
    "\n",
    "\n",
    "clear_output(wait=True)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(item_groups_df[[\"item_id\"]].apply(lambda x: recommender.get_items_emb(x).cpu().numpy().tolist())[\"item_id\"].tolist())\n",
    "\n",
    "metrics = {}\n",
    "for k in range(len(top_k)):\n",
    "    recs = pd.DataFrame([i.values() for i in _recommended_item[k]], columns=[\"sorted_actions\"]).sorted_actions.values.tolist()\n",
    "\n",
    "    metrics[top_k[k]] = {\n",
    "        \"precision\": round(_precision[k] * 100, 4),\n",
    "        \"propfair\": round(_propfair[k] * 100, 4),\n",
    "        \"ufg\": round(_ufg[k], 4),\n",
    "        \"coverage\": round(rm.prediction_coverage(recs, catalog), 4),\n",
    "        \"personalization\": round(rm.personalization(recs) * 100, 4),\n",
    "        \"intra_list_similarity\": round(rm.intra_list_similarity(recs, feature_df), 4),\n",
    "    }\n",
    "\n",
    "# with open(os.path.join(output_path, \"metrics.json\"), \"w\") as f:\n",
    "#     json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: {'precision': 8.7505,\n",
       "  'propfair': 7.6221,\n",
       "  'ufg': 0.0835,\n",
       "  'coverage': 0.2,\n",
       "  'personalization': 4.958,\n",
       "  'intra_list_similarity': 0.5264},\n",
       " 5: {'precision': 8.7713,\n",
       "  'propfair': 7.7919,\n",
       "  'ufg': 0.0854,\n",
       "  'coverage': 0.27,\n",
       "  'personalization': 4.9913,\n",
       "  'intra_list_similarity': 0.5595},\n",
       " 10: {'precision': 8.7871,\n",
       "  'propfair': 8.003,\n",
       "  'ufg': 0.0877,\n",
       "  'coverage': 0.44,\n",
       "  'personalization': 3.7095,\n",
       "  'intra_list_similarity': 0.6127},\n",
       " 15: {'precision': 8.774,\n",
       "  'propfair': 7.937,\n",
       "  'ufg': 0.087,\n",
       "  'coverage': 0.65,\n",
       "  'personalization': 2.9269,\n",
       "  'intra_list_similarity': 0.6349}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in top_k:\n",
    "    _df = pd.DataFrame([i.values() for i in recommended_item], columns=[\"sorted_actions\"])\n",
    "    _df[\"user_id\"] = [list(i.keys())[0] for i in recommended_item]\n",
    "    _item_metadata = pd.DataFrame(dataset[\"item_groups\"].items(), columns=[\"item_id\", \"group\"])\n",
    "\n",
    "    user_column = \"user_id\"\n",
    "    item_column = \"item_id\"\n",
    "    reclist_column = \"sorted_actions\"\n",
    "\n",
    "    recsys_fair = RecsysFair(\n",
    "        df = _df, \n",
    "        supp_metadata = _item_metadata,\n",
    "        user_column = user_column, \n",
    "        item_column = item_column, \n",
    "        reclist_column = reclist_column, \n",
    "    )\n",
    "\n",
    "    fair_column = \"group\"\n",
    "    ex = recsys_fair.exposure(fair_column, k)\n",
    "\n",
    "    fig = ex.show(kind='per_group_norm', column=fair_column)\n",
    "    fig.write_image(os.path.join(output_path, \"exposure_per_group_k{}_v2.png\".format(k)))\n",
    "\n",
    "    fig = ex.show(kind='per_rank_pos', column=fair_column)\n",
    "    fig.write_image(os.path.join(output_path, \"exposure_per_rank_k{}_v2.png\".format(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "RL_ActorCritic_DDPG_Movie_Recommendation.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "23b1c047fd19bf20d4111f807c9e6bee9fdce0e396893bab828ebbcdf9a68cad"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rsrl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/trivago/train.csv')\n",
    "df_meta = pd.read_csv(\"../data/trivago/item_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.action_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"action_type\"] == \"clickout item\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECSYS_CITIES = [\n",
    "    \"Lausanne, Switzerland\",\n",
    "    \"New York, USA\",\n",
    "    \"Barcelona, Spain\",\n",
    "    \"Chicago, USA\",\n",
    "    \"Dublin, Ireland\",\n",
    "    \"Hong Kong, Hong Kong\",\n",
    "    \"Vienna, Austria\",\n",
    "    \"Boston, USA\",\n",
    "    \"Como, Italy\",\n",
    "    \"Vancouver, Canada\",\n",
    "    \"Copenhagen, Denmark\",\n",
    "    \"Rio de Janeiro, Brazil\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"action_type\"] == \"clickout item\")]\n",
    "df = df[df[\"city\"].isin(RECSYS_CITIES)]\n",
    "df = df[[\"timestamp\", \"user_id\", \"reference\", \"impressions\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"timestamp\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"reference\": \"item_id\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"impressions\"] = df[\"impressions\"].apply(lambda x: x.split(\"|\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"item_id\"] = df[\"item_id\"].astype(\"int\")\n",
    "df[\"impressions\"] = df[\"impressions\"].apply(lambda x: [int(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos\"] = df[[\"item_id\", \"impressions\"]].apply(lambda x: x.impressions.index(x.item_id) if x.item_id in x.impressions else -1, axis=1)\n",
    "df = df.drop(df[df[\"pos\"] == -1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode(\"impressions\")\n",
    "df[\"clicked\"] = df[[\"impressions\", \"item_id\"]].apply(lambda x: 1 if int(x[\"impressions\"]) == int(x[\"item_id\"]) else 0, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"user_id\", \"impressions\", \"clicked\", \"pos\"]]\n",
    "df = df.rename(columns={\"impressions\": \"item_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_encoder = preprocessing.LabelEncoder().fit(df.item_id.values)\n",
    "df.item_id = item_encoder.transform(df.item_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encoder = preprocessing.LabelEncoder().fit(df.user_id.values)\n",
    "df.user_id = user_encoder.transform(df.user_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.clicked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"user_id\", \"item_id\", \"clicked\"]].groupby([\"user_id\", \"item_id\"]).max().reset_index()\n",
    "df[\"clicked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/trivago/train_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "from src.model.pmf import PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(preds, truth):\n",
    "    return np.sqrt(np.mean(np.square(preds-truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "epoches = 10000\n",
    "no_cuda = False\n",
    "seed = 1\n",
    "weight_decay = 0.1\n",
    "embedding_feature_size = 50\n",
    "ratio = 0.8\n",
    "lr = 0.0001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    804267\n",
       "1     51676\n",
       "Name: clicked, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/trivago/train_processed.csv\")\n",
    "df.clicked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clicked_norm\"] = df[\"clicked\"].apply(lambda x: 1 if x == 1 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "pos_click = df[df[\"clicked\"] == 1]\n",
    "neg_click = df[df[\"clicked\"] == 0]\n",
    "\n",
    "neg_upsample = resample(neg_click,\n",
    "             replace=True,\n",
    "             n_samples=len(pos_click),\n",
    "             random_state=42)\n",
    "\n",
    "print(neg_upsample.shape)\n",
    "\n",
    "data_upsampled = pd.concat([pos_click, neg_upsample])\n",
    "data_upsampled.clicked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_upsampled[[\"user_id\", \"item_id\", \"clicked_norm\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26306 11972\n"
     ]
    }
   ],
   "source": [
    "NUM_ITEMS = df.item_id.max() + 1\n",
    "NUM_USERS = df.user_id.max() + 1\n",
    "\n",
    "print(NUM_USERS, NUM_ITEMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_data = data[:int(ratio * data.shape[0])]\n",
    "vali_data = data[int(ratio * data.shape[0]): int((ratio+(1-ratio)/2)*data.shape[0])]\n",
    "test_data = data[int((ratio + (1 - ratio) / 2) * data.shape[0]) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda=False\n",
    "\n",
    "# Get CUDA device if available\n",
    "cuda = torch.cuda.is_available()\n",
    " \n",
    "# Set device to CUDA or CPU, depending on availability and desire\n",
    "device = torch.device(\"cuda\" if cuda and no_cuda else \"cpu\")\n",
    " \n",
    "# Generate and apply seeds\n",
    "torch.manual_seed(seed=seed)\n",
    "if cuda:\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.manual_seed(seed=seed)\n",
    " \n",
    "# Specify number of workers for cuda\n",
    "kwargs = {\"num_workers\":1, \"pin_memory\":True} if cuda else {}\n",
    " \n",
    "# Construct Data Loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(torch.from_numpy(train_data), batch_size=batch_size, shuffle=False, **kwargs)\n",
    "test_data_loader = torch.utils.data.DataLoader(torch.from_numpy(test_data), batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = PMF(n_users=NUM_USERS, n_items=NUM_ITEMS, n_factors=embedding_feature_size, no_cuda=no_cuda)\n",
    " \n",
    "# Move model to CUDA if CUDA selected\n",
    "if cuda and not no_cuda:\n",
    "    model.cuda()\n",
    "    print(\"Model moved to CUDA\")\n",
    " \n",
    "# Set loss function\n",
    "loss_function = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "# Set optimizer (uncomment Adam for adam)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training one epoch\n",
    "def train(epoch, train_data_loader):\n",
    "    # Initialize\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    " \n",
    "    # Go through batches\n",
    "    for batch_idx, ele in enumerate(train_data_loader):\n",
    "        # Zero optimizer gradient\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # Extract user_id_nums: row 0, item_id_nums: col 1 , ratings: val 2\n",
    "        row = ele[:, 0]\n",
    "        col = ele[:, 1]\n",
    "        val = ele[:, 2]\n",
    " \n",
    "        # Set to variables\n",
    "        row = Variable(row.long())\n",
    "        if isinstance(col, list):\n",
    "            col = tuple(Variable(c.long()) for c in col)\n",
    "        else:\n",
    "            col = Variable(col.long())\n",
    "        val = Variable(val.float())\n",
    "\n",
    "        # Move data to CUDA\n",
    "        if cuda and not no_cuda:\n",
    "            row = row.cuda()\n",
    "            col = col.cuda()\n",
    "            val = val.cuda()\n",
    " \n",
    "        # Train\n",
    "        preds = model.forward(row, col)\n",
    "        loss = loss_function(preds, val)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # Update epoch loss\n",
    "        epoch_loss += loss.data\n",
    " \n",
    "    epoch_loss /= train_data_loader.dataset.shape[0]\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model\n",
    "count = 0\n",
    "train_loss_list = []\n",
    "last_vali_rmse = None\n",
    "train_rmse_list = []\n",
    "vali_rmse_list = []\n",
    "print(\"parameters are: train ratio:{:f},batch_size:{:d}, epoches:{:d}, weight_decay:{:f}\".format(ratio, batch_size, epoches, weight_decay))\n",
    "print(model)\n",
    "\n",
    "# Go through epochs\n",
    "for epoch in range(1, epoches+1):\n",
    "\n",
    "    # Train epoch\n",
    "    train_epoch_loss = train(epoch, train_data_loader)\n",
    "\n",
    "    # Get epoch loss\n",
    "    train_loss_list.append(train_epoch_loss.cpu())\n",
    "\n",
    "    # Move validation data to CUDA\n",
    "    if cuda and not no_cuda:\n",
    "        vali_row = Variable(torch.from_numpy(vali_data[:, 0]).long()).cuda()\n",
    "        vali_col = Variable(torch.from_numpy(vali_data[:, 1]).long()).cuda()\n",
    "    else:\n",
    "        vali_row = Variable(torch.from_numpy(vali_data[:, 0]).long())\n",
    "        vali_col = Variable(torch.from_numpy(vali_data[:, 1]).long())\n",
    "\n",
    "    # Get validation predictions\n",
    "    vali_preds = model.predict(vali_row, vali_col)\n",
    "\n",
    "    # Calculate train rmse loss\n",
    "    train_rmse = np.sqrt(train_epoch_loss.cpu())\n",
    "\n",
    "    # Calculate validation rmse loss\n",
    "    if cuda and not no_cuda:\n",
    "        vali_rmse = RMSE(vali_preds.cpu().data.numpy(), vali_data[:, 2])\n",
    "    else:\n",
    "        vali_rmse = RMSE(vali_preds.data.numpy(), vali_data[:, 2])\n",
    "\n",
    "    # Add losses to rmse loss lists\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    vali_rmse_list.append(vali_rmse)\n",
    "\n",
    "    print(\"Training epoch:{: d}, training rmse:{: .6f}, vali rmse:{:.6f}\". \\\n",
    "            format(epoch, train_rmse, vali_rmse))\n",
    "\n",
    "    # Early stop condition\n",
    "    if last_vali_rmse and last_vali_rmse < vali_rmse:\n",
    "        break\n",
    "    else:\n",
    "        last_vali_rmse = vali_rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Model\n",
    "\n",
    "# Move test set to CUDA\n",
    "if cuda:\n",
    "    test_row = Variable(torch.from_numpy(test_data[:, 0]).long()).cuda()\n",
    "    test_col = Variable(torch.from_numpy(test_data[:, 1]).long()).cuda()\n",
    "else:\n",
    "    test_row = Variable(torch.from_numpy(test_data[:, 0]).long())\n",
    "    test_col = Variable(torch.from_numpy(test_data[:, 1]).long())\n",
    " \n",
    "# Get test predictions\n",
    "preds = model.predict(test_row, test_col)\n",
    " \n",
    "# Get test rmse loss\n",
    "if cuda:\n",
    "    test_rmse = RMSE(preds.cpu().data.numpy(), test_data[:, 2])\n",
    "else:\n",
    "    test_rmse = RMSE(preds.data.numpy(), test_data[:, 2])\n",
    "print(\"Test rmse: {:f}\".format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots\n",
    "plt.figure(1)\n",
    "plt.plot(range(1, len(train_rmse_list)+1), train_rmse_list, color=\"r\", label=\"train rmse\")\n",
    "plt.plot(range(1, len(vali_rmse_list)+1), vali_rmse_list, color=\"b\", label=\"test rmse\")\n",
    "plt.legend()\n",
    "plt.annotate(r\"train=%f\" % (train_rmse_list[-1]), xy=(len(train_rmse_list), train_rmse_list[-1]),\n",
    "             xycoords=\"data\", xytext=(-30, 30), textcoords=\"offset points\", fontsize=10,\n",
    "             arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3, rad=.2\"))\n",
    "plt.annotate(r\"vali=%f\" % (vali_rmse_list[-1]), xy=(len(vali_rmse_list), vali_rmse_list[-1]),\n",
    "             xycoords=\"data\", xytext=(-30, 30), textcoords=\"offset points\", fontsize=10,\n",
    "             arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3, rad=.2\"))\n",
    "plt.xlim([1, len(train_rmse_list)+10])\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"RMSE Curve in Training Process\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "path_to_trained_pmf = \"../model/pmf/trivago_emb_{:d}_ratio_{:f}_bs_{:d}_e_{:d}_wd_{:f}_lr_{:f}_trained_pmf.pt\".format(embedding_feature_size, ratio, batch_size, len(train_rmse_list), weight_decay, lr)\n",
    "torch.save(model.state_dict(), path_to_trained_pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =  0\n",
    "(model.predict(\n",
    "    torch.tensor([data[idx][0]]).long().to(\"cuda\"), \n",
    "    torch.tensor([data[idx][1]]).long().to(\"cuda\")\n",
    ").cpu().data[0] + 1) / 2, (data[idx][2] + 1) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/trivago/train_processed.csv\")\n",
    "df.clicked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dict = {user: [] for user in set(df[\"user_id\"])}\n",
    "\n",
    "ratings_df_gen = df.iterrows()\n",
    "users_dict_positive_items = {\n",
    "    user: [] for user in set(df[\"user_id\"])\n",
    "}\n",
    "for data in ratings_df_gen:\n",
    "    users_dict[data[1][\"user_id\"]].append(\n",
    "        (data[1][\"item_id\"], data[1][\"clicked\"])\n",
    "    )\n",
    "    if data[1][\"clicked\"] > 0:\n",
    "        users_dict_positive_items[data[1][\"user_id\"]].append(\n",
    "            (data[1][\"item_id\"], data[1][\"clicked\"])\n",
    "        )\n",
    "users_history_lens = [\n",
    "    len(users_dict_positive_items[u])\n",
    "    for u in set(df[\"user_id\"])\n",
    "]\n",
    "\n",
    "users_num = max(df[\"user_id\"]) + 1\n",
    "items_num = max(df[\"item_id\"]) + 1\n",
    "\n",
    "print(users_num, items_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users_num = int(users_num * 0.8)\n",
    "train_users_dict = {k: users_dict.get(k) for k in range(0, train_users_num - 1)}\n",
    "train_users_history_lens = users_history_lens[:train_users_num]\n",
    "\n",
    "# Evaluating setting\n",
    "eval_users_num = int(users_num * 0.2)\n",
    "eval_users_dict = {\n",
    "    k: users_dict[k] for k in range(users_num - eval_users_num, users_num)\n",
    "}\n",
    "eval_users_history_lens = users_history_lens[-eval_users_num:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "with open(\"../data/trivago/train_users_dict.pkl\", \"wb\") as file:\n",
    "    pickle.dump(train_users_dict, file)\n",
    "\n",
    "with open(\"../data/trivago/train_users_history_lens.pkl\", \"wb\") as file:\n",
    "    pickle.dump(train_users_history_lens, file)\n",
    "\n",
    "with open(\"../data/trivago/eval_users_dict.pkl\", \"wb\") as file:\n",
    "    pickle.dump(eval_users_dict, file)\n",
    "\n",
    "with open(\"../data/trivago/eval_users_history_lens.pkl\", \"wb\") as file:\n",
    "    pickle.dump(eval_users_history_lens, file)\n",
    "\n",
    "with open(\"../data/trivago/users_history_lens.pkl\", \"wb\") as file:\n",
    "    pickle.dump(users_history_lens, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.geometric(p=0.35, size=items_num)\n",
    "w = z%10 \n",
    "w = [i if i > 0 else 10 for i in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_group = {i: w[i] for i in range(items_num)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/trivago/item_groups.pkl\", \"wb\") as file:\n",
    "    pickle.dump(item_group, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "with open(\"../data/trivago/train_users_dict.pkl\", \"rb\") as pkl_file:\n",
    "    dataset[\"train_users_dict\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(\"../data/trivago/train_users_history_lens.pkl\", \"rb\") as pkl_file:\n",
    "    dataset[\"train_users_history_lens\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(\"../data/trivago/eval_users_dict.pkl\", \"rb\") as pkl_file:\n",
    "    dataset[\"eval_users_dict\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(\"../data/trivago/eval_users_history_lens.pkl\", \"rb\") as pkl_file:\n",
    "    dataset[\"eval_users_history_lens\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(\"../data/trivago/users_history_lens.pkl\", \"rb\") as pkl_file:\n",
    "    dataset[\"users_history_lens\"] = pickle.load(pkl_file)\n",
    "\n",
    "with open(\"../data/trivago/item_groups.pkl\", \"rb\") as pkl_file:\n",
    "    dataset[\"item_groups\"] = pickle.load(pkl_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(dataset[\"train_users_history_lens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_users = []\n",
    "for u in dataset[\"train_users_dict\"].keys():\n",
    "    positive_items = [data[0] for data in dataset[\"train_users_dict\"][u] if data[1] > 0]\n",
    "    if len(positive_items) > 1:\n",
    "        available_users.append(u)\n",
    "len(available_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23b1c047fd19bf20d4111f807c9e6bee9fdce0e396893bab828ebbcdf9a68cad"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
